

I have implemented a BigramModel manually and then implemented the same model using
the NeuralNetwork module. Both of these models have a much higher loss than the Transformer architecture hereby applied






If you want you can go through the steps and compare both models using the .ipynb file (you can use jupyter notebook for this)
otherwise if you just want to train the Transformer model and generate text you can use 'python TransformerModel.py'
