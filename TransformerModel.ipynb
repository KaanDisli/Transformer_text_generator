{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "925787ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "with open(\"Shakespeare_text.txt\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "\n",
    "\n",
    "learning_rate = 3e-4\n",
    "text_size = len(text)\n",
    "batch_size = 64\n",
    "context_size = 256\n",
    "dim = 2\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "training_text  = text[:text_size]\n",
    "training_size = len(training_text)\n",
    "val_text = text[training_size:]\n",
    "val_size = len(val_text)\n",
    "embd_size =384\n",
    "head_size = 64\n",
    "n_layer = 6 \n",
    "dropout  = 0.3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(1337)\n",
    "nb_heads = 6\n",
    "dont_train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b78f7ab-072d-4ced-8864-50d479c885e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda s: [stoi[char] for char in s ]\n",
    "decode = lambda s: ''.join([itos[i] for i in s])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b02c12a-8ea4-4ad6-87fd-c2f791d25786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[56, 40, 43,  ...,  1, 46, 53],\n",
       "         [40, 48, 43,  ..., 46, 43, 63],\n",
       "         [57,  1, 46,  ...,  1, 53, 59],\n",
       "         ...,\n",
       "         [47, 52,  1,  ..., 39, 56, 51],\n",
       "         [41, 46,  1,  ..., 57, 47, 56],\n",
       "         [ 1, 42, 43,  ..., 39, 52, 57]]),\n",
       " tensor([[40, 43, 39,  ..., 46, 53, 61],\n",
       "         [48, 43, 41,  ..., 43, 63,  1],\n",
       "         [ 1, 46, 43,  ..., 53, 59, 56],\n",
       "         ...,\n",
       "         [52,  1, 54,  ..., 56, 51, 57],\n",
       "         [46,  1, 42,  ..., 47, 56, 56],\n",
       "         [42, 43, 39,  ..., 52, 57, 58]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generates a random batch of characters with (context_size, batch_size)\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "def get_batch(): #FIXED INEFFICIENCY PROBLEM, TENSORS MORE EFFICIENT THAN STRINGS\n",
    "    #data = torch.tensor(encode(training_text), dtype=torch.long, device=device)  THIS LINE CREATED A NEW TENSOR EVERY TIME WE GET A NEW BATCH SLOWING TRAINING\n",
    "    ix = torch.randint(len(data) - context_size, (batch_size,), device=device)\n",
    "    x = torch.stack([data[i:i+context_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+context_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "918cbfb5-3db4-49db-bcce-bf800ba19b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_batch():\n",
    "    ix = torch.randint(val_size - context_size, (batch_size,))\n",
    "    x = [val_text[i:i+context_size] for i in ix]\n",
    "    x = [encode(char) for char  in x]\n",
    "    x = torch.tensor(x)\n",
    "    label = [val_text[i+1:i+context_size+1] for i in ix]\n",
    "    label = [encode(char) for char in label ] \n",
    "    label = torch.tensor(label)\n",
    "    return x , label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7695f33b-936b-4b95-a490-a569a13887ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_loss(model): \n",
    "    X, labels = get_batch() #X: (batch_size , context_size), labels: (batch_size , context_size)\n",
    "    loss_fn = nn.CrossEntropyLoss() #takes (batch_size * context_size, vocab_size) and (batch_size * context_size)\n",
    "    loss = 0\n",
    "    logit_list = []\n",
    "    for idx in X.flatten():\n",
    "        _, logits = model.predict(idx.item()) \n",
    "        logit_list.append(logits.unsqueeze(0)) #we add another dimension so we can concatanate the list into a tensor later more efficiently.  \n",
    "        #Currently a list of (batch_size * context_size , (1,vocabsize))\n",
    "                         \n",
    "    labels = labels.flatten() #(batch_size * context_size)\n",
    "    logit_tensor = torch.cat(logit_list,dim=0)    #The tensors must have the same shape in all dimensions except the one specified by dim. \n",
    "    #All elements in the list are concatanated along the first dimension to produce a tensor  (batch_size * context_size, vocab_size) \n",
    "    loss = loss_fn(logit_tensor,labels)\n",
    "    return loss.item()\n",
    "    \n",
    "            \n",
    "            \n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86cb3d07-68a7-4943-be5d-ba7ed6fc0dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constructing the Bigram Model manually without the Neural Network Module\n",
    "class BigramModelManual(): \n",
    "    def __init__(self, training_text,vocab): \n",
    "        self.text = text\n",
    "        self.vocab = vocab \n",
    "        self.training_text = training_text\n",
    "        self.vocab_size = len(vocab) \n",
    "        self.matrice = np.zeros((self.vocab_size,self.vocab_size)) #Matrix Vocab_Size x Vocab_Size\n",
    "        self.training_size = len(training_text)\n",
    "    \n",
    "    def train(self):  #normalizing the matrice based on the frequency of the following character\n",
    "        for i in range(self.training_size-1):\n",
    "            self.matrice[self.training_text[i],self.training_text[i+1]] +=1            \n",
    "        for row in range(len(self.matrice)):\n",
    "            row_sum = self.matrice[row].sum()\n",
    "            if row_sum > 0:  # Avoid division by zero\n",
    "                    self.matrice[row] /= row_sum\n",
    "\n",
    "    def get_matrice(self):\n",
    "        return self.matrice\n",
    "\n",
    "    def get_logits(self,idx):\n",
    "         torch.tensor(self.matrice[idx])\n",
    "        \n",
    "    def predict(self,idx): #idx is the input character\n",
    "        selected_value = np.random.choice(self.vocab, p=self.matrice[idx])\n",
    "        logits = torch.tensor(self.matrice[idx])\n",
    "        return encode(selected_value)[0], logits\n",
    "    \n",
    "        \n",
    "        \n",
    "    def generate(self,generation_limit,initial_character=' '):\n",
    "        generated_text = []\n",
    "        idx = encode(initial_character)[0]\n",
    "        for i in range(generation_limit):  \n",
    "            pred, logits = self.predict(idx)\n",
    "            generated_text.append(pred)\n",
    "            idx = generated_text[-1]\n",
    "        return decode(generated_text)\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dc68f57-fad3-4723-b088-28c688fd2581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nthr VANShirenl, ori'TI ps go hurggor liloon OLoss\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m50\u001b[39m))\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;124m\"\u001b[39m , \u001b[43mestimate_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[13], line 14\u001b[0m, in \u001b[0;36mestimate_loss\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     12\u001b[0m logit_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(logit_list,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)    \u001b[38;5;66;03m#The tensors must have the same shape in all dimensions except the one specified by dim. \u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#All elements in the list are concatanated along the first dimension to produce a tensor  (batch_size * context_size, vocab_size) \u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogit_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\Kaan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kaan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Kaan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1293\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kaan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:3479\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3478\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3480\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3483\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3486\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)"
     ]
    }
   ],
   "source": [
    "#Generating text with the manual BigramModel\n",
    "\n",
    "model = BigramModelManual(encode(training_text),chars)\n",
    "matrix = model.get_matrice()\n",
    "model.train()\n",
    "print(model.generate(50))\n",
    "print(\"Loss: \" , estimate_loss(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dc5b921-8d78-43c2-882d-18a50f3c953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "#BigramModel using the Neural Network module\n",
    "class BigramModel(nn.Module):\n",
    "    def __init__(self,vocab_size): \n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size,vocab_size) #initializing the embedding table (vocabsize,vocab_size)\n",
    "\n",
    "    def forward(self,idx,targets=None):\n",
    "        logits = self.token_embedding_table(idx) #For each token in the input tensor idx, the model retrieves its corresponding logits. B,T -> B,T,C\n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits_flatten = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits_flatten,targets)\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self,idx,max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            #idx = B,T\n",
    "            logits,_  = self.forward(idx) # we get the logits for each Batch (B,T,C\n",
    "            logits = logits[:,-1,:] #convert logits to B,C (taking out the last column of every batch )\n",
    "            proba = F.softmax(logits, dim=-1)  #convert the last dimension to probabilities\n",
    "            new_token= torch.multinomial(proba,num_samples = 1) #generate new token based on proabilities (B,1)\n",
    "            idx = torch.cat((idx,new_token),dim=1)\n",
    "            \n",
    "        return idx\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5638a317-8458-4410-8a35-03485ff07319",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (\u001b[38;5;241m10000\u001b[39m):\n\u001b[0;32m     10\u001b[0m     X, labels \u001b[38;5;241m=\u001b[39m get_batch() \u001b[38;5;66;03m#We get a random batch \u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     logits, loss \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#We calculate the logits obtained from this batch \u001b[39;00m\n\u001b[0;32m     12\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m#Not sure what this does\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m#Computes the gradients of the loss\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[16], line 9\u001b[0m, in \u001b[0;36mBigramModel.forward\u001b[1;34m(self, idx, targets)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,idx,targets\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m----> 9\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_embedding_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#For each token in the input tensor idx, the model retrieves its corresponding logits. B,T -> B,T,C\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m targets \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kaan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kaan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Kaan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kaan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "#Trainign the BigramModule weights\n",
    "X, labels = get_batch()\n",
    "m = BigramModel(vocab_size)\n",
    "\n",
    "idx = torch.zeros((1,1), dtype = torch.long)\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)\n",
    "\n",
    "#loss, optimizer and logits are connected through nn.Embedding\n",
    "for iteration in range (10000):\n",
    "    X, labels = get_batch() #We get a random batch \n",
    "    logits, loss = m.forward(X,targets=labels) #We calculate the logits obtained from this batch \n",
    "    optimizer.zero_grad(set_to_none=True) #Not sure what this does\n",
    "    loss.backward() #Computes the gradients of the loss\n",
    "    optimizer.step() # Updates the weights of the model\n",
    "print(loss.item())\n",
    "\n",
    "print(decode(m.generate(idx,100)[0].tolist()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c2c410a-b7af-4b6e-a296-66ac70589888",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self,size):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.key = nn.Linear(embd_size,size, bias= False) \n",
    "        self.query = nn.Linear(embd_size,size, bias= False)\n",
    "        self.value = nn.Linear(embd_size,size, bias= False)\n",
    "        self.dropout = nn.Dropout(dropout) #we dropout and set some affinities to 0 so that the model doesnt overly really on any one token \n",
    "        self.register_buffer('tril', torch.tril(torch.ones(context_size, context_size)))\n",
    "\n",
    "    def forward(self,x):\n",
    "        k = self.key(x) #we perform linear transformation on x and get key vectors B T 4\n",
    "        q = self.query(x)  #we perform linear transformation on x and get query vectors B T 4\n",
    "        v = self.value(x) #we perform linear transformation on x and get value vectors B T 4\n",
    "        self.weights = q @ k.transpose(-2,-1)*self.size ** -0.5 #we perform matrix multiplication on key and query matrice and scale it down by square root of head_Size do reduce variance for the softmax\n",
    "        #B T 4 @ B 4 T -> B T T For every token this represents the affinity with other tokens in the same context\n",
    "        \n",
    "        self.weights = self.weights.masked_fill(self.tril[:context_size, :context_size] == 0, float('-inf')) #we perform triangular masking to disregard tokens that are positionally in front of the token we are analysing \n",
    "        self.weights = F.softmax(self.weights, dim= -1)\n",
    "        self.weights = self.dropout(self.weights)\n",
    "        output = self.weights @ v \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "031e4185-efe2-4c3c-8be9-a066568e257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We combine multiple heads into 1 multihead attention block\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,nb_heads,head_size):\n",
    "        super().__init__()\n",
    "        self.nb_heads = nb_heads\n",
    "        self.head_size = head_size\n",
    "        self.Heads = nn.ModuleList([Head(head_size) for i in range(nb_heads) ])\n",
    "        self.proj = nn.Linear(embd_size,embd_size) #Without self.proj, the heads would remain separate and untransformed, which could limit the model's ability to integrate the insights gained from different attention heads.\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = torch.cat ( [heads.forward(x) for heads in self.Heads], dim = 2  )\n",
    "        out = self.proj(out)\n",
    "        out = self.dropout(out)\n",
    "        return out #We concatanate all the invidiual heads to form an embd_size mutli_head\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88d808e4-e3d9-4461-802d-997234285a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The outputs from the MHA are fedforward into the next block using an activation function and linear transformation\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(embd_size, 4 * embd_size), nn.ReLU(),nn.Linear(4 * embd_size,embd_size), # multiplying by 4 allows to  increase the size of the skip connection pathway?\n",
    "  nn.Dropout(dropout)      ) #We set some features to 0 so that the model doesnt overly really on any single feature of a token\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d5448d1-4a04-48ea-a714-d4e1e2575df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self,nb_heads,head_size):\n",
    "        super().__init__()\n",
    "        self.sa = MultiHeadAttention(nb_heads,head_size) \n",
    "        self.ffwd = FeedForward()\n",
    "        self.ln_1 = nn.LayerNorm(embd_size)#We normalize the features of each token among themselves\n",
    "        self.ln_2 = nn.LayerNorm(embd_size) \n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.ln_1(x) + self.sa(x)  # Normalization BEFORE residual\n",
    "        x = self.ln_2(x) + self.ffwd(x)  # \n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c049f36c-2f7a-48b7-a0ce-060620ddb050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self,embd_size): \n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size,embd_size) #initializing the token embedding table for the identity of each token (embd_size,embd_size)\n",
    "        self.positional_embedding_table = nn.Embedding(context_size ,embd_size).to(device) #initializing the positional embedding table for each position in the context \n",
    "        self.lm_head = nn.Linear(embd_size,vocab_size)\n",
    "        self.blocks = nn.Sequential( *[Block(nb_heads,head_size) for _ in range(n_layer)] ) \n",
    "        self.ln_f =  nn.LayerNorm(embd_size)\n",
    "    def forward(self,idx,targets=None):\n",
    "        idx = idx.to(device, dtype=torch.long)\n",
    "        seq_len = idx.size(1)\n",
    "        token_positional_value = self.positional_embedding_table(\n",
    "    torch.arange(seq_len, device=self.positional_embedding_table.weight.device, dtype=torch.long)\n",
    ")\n",
    "        token_embed_value = self.token_embedding_table(idx) \n",
    "        \n",
    " \n",
    "        pos_and_embed_value = token_positional_value + token_embed_value #we sum the identity and the position of the token B , T, embd_size\n",
    "        #4 8 32\n",
    "\n",
    "\n",
    "        x = self.blocks(pos_and_embed_value) #we forward the values \n",
    "        logits = self.lm_head(x) #we transform the output into a class size array to get the logits\n",
    "        if targets == None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits_flatten = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            targets = targets.to(device)\n",
    "            loss = F.cross_entropy(logits_flatten,targets)\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self,idx,max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            if context_size > len(idx[0]):\n",
    "                new_token = torch.zeros((1,context_size - len(idx)), dtype = torch.long, device=device) #T, make sure the new token is on the gpu \n",
    "                idx = torch.cat((idx,new_token),dim=1)\n",
    "                logits,_  = self.forward(idx) \n",
    "            else:\n",
    "                logits,_  = self.forward(idx[: , -context_size:]) # we get the logits for each Batch (B,T,C)\n",
    "            logits = logits[:,-1,:] #convert logits to B,C (taking out the last column of every batch )\n",
    "            proba = F.softmax(logits, dim=-1)  #convert the last dimension to probabilities\n",
    "            new_token= torch.multinomial(proba,num_samples = 1) #generate new token based on proabilities (B,1)\n",
    "            idx = torch.cat((idx,new_token),dim=1)\n",
    "           \n",
    "            \n",
    "        return idx\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed44402f-9420-4669-b0b5-3cb6d5894e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 0\n",
      "Training loss\n",
      "4.2836432456970215\n",
      "Iteration 1\n",
      "Iteration 2\n",
      "Iteration 3\n",
      "Iteration 4\n",
      "Iteration 5\n",
      "Iteration 6\n",
      "Iteration 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#Training\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#loss, optimizer and logits are connected through nn.Embedding\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (\u001b[38;5;241m2000\u001b[39m):\n\u001b[1;32m---> 10\u001b[0m     X, labels \u001b[38;5;241m=\u001b[39m \u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#We get a random batch \u001b[39;00m\n\u001b[0;32m     11\u001b[0m     X, labels \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m# Move data to GPU\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     logits, loss \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mforward(X,targets\u001b[38;5;241m=\u001b[39mlabels) \u001b[38;5;66;03m#We calculaote the logits obtained from this batch \u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m, in \u001b[0;36mget_batch\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_batch\u001b[39m(): \u001b[38;5;66;03m#FIXED INEFFICIENCY PROBLEM, TENSORS MORE EFFICIENT THAN STRINGS\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m#data = torch.tensor(encode(training_text), dtype=torch.long, device=device)  THIS LINE CREATED A NEW TENSOR EVERY TIME WE GET A NEW BATCH SLOWING TRAINING\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     ix \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m-\u001b[39m context_size, (batch_size,), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m----> 6\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([data[i:i\u001b[38;5;241m+\u001b[39mcontext_size] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ix])\n\u001b[0;32m      7\u001b[0m     y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([data[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:i\u001b[38;5;241m+\u001b[39mcontext_size\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ix])\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m = TransformerModel(embd_size)\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)\n",
    "m.to(device)  # Move the model to GPU\n",
    "\n",
    "  \n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=2000) #adjusts the learning rate\n",
    "#Training\n",
    "#loss, optimizer and logits are connected through nn.Embedding\n",
    "for iteration in range (2000):\n",
    "    X, labels = get_batch() #We get a random batch \n",
    "    X, labels = X.to(device), labels.to(device) # Move data to GPU\n",
    "    logits, loss = m.forward(X,targets=labels) #We calculaote the logits obtained from this batch \n",
    "    optimizer.zero_grad(set_to_none=True) #Not sure what this does\n",
    "    loss.backward() #Computes the gradients of the loss\n",
    "    optimizer.step() # Updates the weights of the model\n",
    "    print(\"Iteration\", iteration)\n",
    "    if iteration % 50 == 0:\n",
    "        print(\"Iteration\", iteration)\n",
    "        print(\"Training loss\")\n",
    "        print(loss.item())\n",
    "        \n",
    "        \n",
    "\n",
    "print(\"Training loss\")\n",
    "print(loss.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51454e0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_validation_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (\u001b[38;5;241m10000\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     X, labels \u001b[38;5;241m=\u001b[39m \u001b[43mget_validation_batch\u001b[49m() \u001b[38;5;66;03m#We get a random batch \u001b[39;00m\n\u001b[0;32m      3\u001b[0m     logits, loss \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mforward(X,targets\u001b[38;5;241m=\u001b[39mlabels) \u001b[38;5;66;03m#We calculate the logits obtained from this batch \u001b[39;00m\n\u001b[0;32m      4\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m#Not sure what this does\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_validation_batch' is not defined"
     ]
    }
   ],
   "source": [
    "for iteration in range (10000):\n",
    "    X, labels = get_validation_batch() #We get a random batch \n",
    "    logits, loss = m.forward(X,targets=labels) #We calculate the logits obtained from this batch \n",
    "    optimizer.zero_grad(set_to_none=True) #Not sure what this does\n",
    "    loss.backward() #Computes the gradients of the loss\n",
    "    optimizer.step() # Updates the weights of the model\n",
    "print(\"Validation loss\")\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf57641-1334-4f14-9452-5d13b1aa93db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaan\\AppData\\Local\\Temp\\ipykernel_5332\\246982697.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  m.load_state_dict(torch.load('model_weights.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CUTUSeMOLor:\n",
      "Nurse:\n",
      "I know a my coming told you not villain you, he's a fools ta'not!\n",
      "\n",
      "AUTONUS:\n",
      "Let the honourable of your unclest pridegrate.\n",
      "\n",
      "Third Citizen:\n",
      "Be your admisher, there by you his weath-harking! hear it calls\n",
      "He, I'll doght the stand to seeman: therefore thou woldst be that\n",
      "natives, of my cog, wothing a brozen and\n",
      "bantic-led few on the night on virtue peace, against\n",
      "And it canst tell upon a milf, those tripps\n",
      "In peace. Musicians that incled liege,\n",
      "And Romeo still for celter husband met them along:\n",
      "Go, crave way, and with Ravensparited is not.\n",
      "\n",
      "CATES:\n",
      "March, O, naply, or never half tell of such are\n",
      "My ories for the jointa, being readed,\n",
      "To make thy things is thy husband's death,\n",
      "We shall wish thy words word. That devour's the good\n",
      "Are the quiter's teats o' the curtainted new;\n",
      "For he, she hadst them strange, they ship for war.\n",
      "Shalt now adverce there to of Mercurel,\n",
      "Yet prepain and me begot in my fornish,\n",
      "And here that thereto the prayer water not.\n",
      "Was, since 'twas no to ma\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0]], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Text generation\n",
    "if dont_train:\n",
    "    m.load_state_dict(torch.load('model_weights.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce5d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.zeros((1,1), dtype = torch.long, device=device) #Initalize with an empty character, making sure the tensor is on gpu\n",
    "print(decode(m.generate(idx,1000)[0].tolist()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
